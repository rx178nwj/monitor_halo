#!/usr/bin/env python3
"""
è¦‹å®ˆã‚Šãƒãƒ­ (Mimamori Halo) - ãƒ¡ã‚¤ãƒ³ç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãŠçˆ¶æ§˜ã®å®‰å…¨ã‚’è¦‹å®ˆã‚Šã¾ã™
"""

import cv2
import numpy as np
import json
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from onvif import ONVIFCamera
from ultralytics import YOLO
from skimage.metrics import structural_similarity as ssim

# è¨­å®šèª­ã¿è¾¼ã¿
CONFIG_PATH = Path(__file__).parent.parent / "config" / "settings.json"
with open(CONFIG_PATH, 'r') as f:
    CONFIG = json.load(f)

DATA_DIR = Path(__file__).parent.parent / "data"
LOG_DIR = Path(__file__).parent.parent / "logs"

class MimamoriHalo:
    """è¦‹å®ˆã‚Šãƒãƒ­ - ãƒ¡ã‚¤ãƒ³ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        print("ğŸ¤– è¦‹å®ˆã‚Šãƒãƒ­ã‚’èµ·å‹•ä¸­...")
        
        # YOLOãƒ¢ãƒ‡ãƒ«
        self.yolo = YOLO('yolov8n.pt')
        
        # ONVIFã‚«ãƒ¡ãƒ©
        self.camera = ONVIFCamera(
            CONFIG['camera']['host'],
            CONFIG['camera']['onvif_port'],
            CONFIG['camera']['username'],
            CONFIG['camera']['password']
        )
        self.ptz_service = self.camera.create_ptz_service()
        self.media_service = self.camera.create_media_service()
        self.ptz_token = self.media_service.GetProfiles()[0].token
        
        # çŠ¶æ…‹ç®¡ç†
        self.state = "not_detected"
        self.interval = CONFIG['scan_intervals']['not_detected']
        
        # å‰å›æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¡ãƒ¢ãƒªã®ã¿ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é…æ…®ï¼‰
        self.previous_person_crop = None
        self.previous_bbox = None
        self.last_detection_time = None
        
        # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿
        self.today_data = self.load_today_data()
        
        print("âœ… è¦‹å®ˆã‚Šãƒãƒ­èµ·å‹•å®Œäº†")
    
    def load_today_data(self):
        """æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        today = datetime.now().strftime("%Y-%m-%d")
        data_file = DATA_DIR / f"{today}.json"
        
        if data_file.exists():
            with open(data_file, 'r') as f:
                return json.load(f)
        else:
            return {
                "date": today,
                "events": [],
                "summary": {
                    "first_activity": None,
                    "last_activity": None,
                    "total_detections": 0,
                    "lying_events": 0,
                    "alerts": []
                }
            }
    
    def save_today_data(self):
        """æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆåŸå­çš„ãªæ›¸ãè¾¼ã¿ï¼‰"""
        today = datetime.now().strftime("%Y-%m-%d")
        data_file = DATA_DIR / f"{today}.json"
        temp_file = DATA_DIR / f"{today}.json.tmp"

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(self.today_data, f, ensure_ascii=False, indent=2)

        # åŸå­çš„ã«ç½®ãæ›ãˆ
        temp_file.replace(data_file)
    
    def is_night_mode(self):
        """å¤œé–“ãƒ¢ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯"""
        if not CONFIG['night_mode']['enabled']:
            return False
        
        now = datetime.now().time()
        start = datetime.strptime(CONFIG['night_mode']['start_time'], "%H:%M").time()
        end = datetime.strptime(CONFIG['night_mode']['end_time'], "%H:%M").time()
        
        if start < end:
            return start <= now <= end
        else:  # æ—¥ã‚’ã¾ãŸãå ´åˆ
            return now >= start or now <= end
    
    def move_camera(self, angle):
        """ã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®šè§’åº¦ã«ç§»å‹•"""
        # æ­£è¦åŒ–ã•ã‚ŒãŸé€Ÿåº¦ï¼ˆ-1 to 1ï¼‰
        speed = 0.3 if angle > 0 else -0.3 if angle < 0 else 0

        if speed != 0:
            request = self.ptz_service.create_type('ContinuousMove')
            request.ProfileToken = self.ptz_token
            request.Velocity = {'PanTilt': {'x': speed, 'y': 0}}
            self.ptz_service.ContinuousMove(request)

            # ç§»å‹•æ™‚é–“ã‚’è¨ˆç®—ï¼ˆè§’åº¦ã«å¿œã˜ã¦ï¼‰
            move_time = abs(angle) / 30.0 * 0.5  # 30åº¦ã§0.5ç§’
            time.sleep(move_time)

            # åœæ­¢
            stop_request = self.ptz_service.create_type('Stop')
            stop_request.ProfileToken = self.ptz_token
            self.ptz_service.Stop(stop_request)

        time.sleep(0.5)  # å®‰å®šå¾…æ©Ÿ

    def move_camera_smooth(self, pan_speed, tilt_speed=0, duration=0.5):
        """ã‚«ãƒ¡ãƒ©ã‚’æ»‘ã‚‰ã‹ã«ç§»å‹•ï¼ˆè¿½å°¾ç”¨ï¼‰"""
        if pan_speed != 0 or tilt_speed != 0:
            request = self.ptz_service.create_type('ContinuousMove')
            request.ProfileToken = self.ptz_token
            request.Velocity = {'PanTilt': {'x': pan_speed, 'y': tilt_speed}}
            self.ptz_service.ContinuousMove(request)

            time.sleep(duration)

            # åœæ­¢
            stop_request = self.ptz_service.create_type('Stop')
            stop_request.ProfileToken = self.ptz_token
            self.ptz_service.Stop(stop_request)
    
    def capture_snapshot(self):
        """ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—"""
        temp_file = "/tmp/mimamori_snapshot.jpg"
        
        subprocess.run([
            'ffmpeg', '-rtsp_transport', 'tcp',
            '-i', f"rtsp://{CONFIG['camera']['username']}:{CONFIG['camera']['password']}@{CONFIG['camera']['host']}:{CONFIG['camera']['rtsp_port']}/stream1",
            '-frames:v', '1', '-q:v', '2',
            temp_file, '-y'
        ], capture_output=True, timeout=10)
        
        img = cv2.imread(temp_file)
        return img
    
    def detect_person(self, image):
        """äººç‰©æ¤œå‡º + å§¿å‹¢æ¨å®š"""
        results = self.yolo(image, verbose=False)
        detections = results[0].boxes
        
        persons = []
        for box in detections:
            cls_id = int(box.cls[0])
            if cls_id == 0:  # person
                conf = float(box.conf[0])
                bbox = box.xyxy[0].tolist()
                
                # å§¿å‹¢æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼šç¸¦æ¨ªæ¯”ã§åˆ¤å®šï¼‰
                x1, y1, x2, y2 = bbox
                width = x2 - x1
                height = y2 - y1
                aspect_ratio = height / width if width > 0 else 0
                
                if aspect_ratio > 1.5:
                    posture = "standing"
                elif aspect_ratio > 0.8:
                    posture = "sitting"
                else:
                    posture = "lying"
                
                persons.append({
                    'bbox': bbox,
                    'confidence': conf,
                    'posture': posture,
                    'aspect_ratio': aspect_ratio
                })
        
        return persons
    
    def compare_with_previous(self, current_image, person):
        """å‰å›æ¤œå‡ºã¨æ¯”è¼ƒ"""
        if self.previous_person_crop is None:
            # åˆå›æ¤œå‡º
            self.save_current_detection(current_image, person['bbox'])
            return {
                'same_position': False,
                'similarity_ssim': 0,
                'position_diff': 0
            }
        
        # ç¾åœ¨ã®äººç‰©é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
        x1, y1, x2, y2 = map(int, person['bbox'])
        current_crop = current_image[y1:y2, x1:x2]
        
        # ã‚µã‚¤ã‚ºã‚’å‰å›ã¨åˆã‚ã›ã‚‹
        prev_h, prev_w = self.previous_person_crop.shape[:2]
        current_resized = cv2.resize(current_crop, (prev_w, prev_h))
        
        # SSIMè¨ˆç®—
        gray1 = cv2.cvtColor(self.previous_person_crop, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(current_resized, cv2.COLOR_BGR2GRAY)
        similarity, _ = ssim(gray1, gray2, full=True)
        
        # ä½ç½®å¤‰åŒ–
        center1_x = (self.previous_bbox[0] + self.previous_bbox[2]) / 2
        center1_y = (self.previous_bbox[1] + self.previous_bbox[3]) / 2
        center2_x = (person['bbox'][0] + person['bbox'][2]) / 2
        center2_y = (person['bbox'][1] + person['bbox'][3]) / 2
        position_diff = np.sqrt((center2_x - center1_x)**2 + (center2_y - center1_y)**2)
        
        # åˆ¤å®š
        same_position = (
            similarity > CONFIG['fall_detection']['similarity_threshold'] and
            position_diff < CONFIG['fall_detection']['position_tolerance']
        )
        
        # ç¾åœ¨ã®æ¤œå‡ºã‚’ä¿å­˜
        self.save_current_detection(current_image, person['bbox'])
        
        return {
            'same_position': same_position,
            'similarity_ssim': similarity,
            'position_diff': position_diff
        }
    
    def save_current_detection(self, image, bbox):
        """ç¾åœ¨ã®æ¤œå‡ºã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜"""
        x1, y1, x2, y2 = map(int, bbox)
        self.previous_person_crop = image[y1:y2, x1:x2].copy()
        self.previous_bbox = bbox
    
    def scan_area(self):
        """ã‚¨ãƒªã‚¢ã‚¹ã‚­ãƒ£ãƒ³"""
        positions = CONFIG['camera']['scan_positions']
        results = {}
        
        for angle in positions:
            self.move_camera(angle)
            image = self.capture_snapshot()
            persons = self.detect_person(image)
            
            results[angle] = {
                'detected': len(persons) > 0,
                'persons': persons
            }
            
            # äººãŒè¦‹ã¤ã‹ã£ãŸã‚‰è¿½å°¾ãƒ¢ãƒ¼ãƒ‰ã¸
            if persons:
                tracked_person = self.track_person(persons[0], image)
                return angle, image, tracked_person

            # ç”»åƒå‰Šé™¤ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ï¼‰
            del image

        # ãƒ›ãƒ¼ãƒ ãƒã‚¸ã‚·ãƒ§ãƒ³ã«æˆ»ã‚‹
        self.move_camera(CONFIG['camera']['home_position'])

        return None, None, None

    def track_person(self, person, initial_image):
        """äººç‰©ã‚’1åˆ†é–“è¿½å°¾"""
        tracking_enabled = CONFIG.get('tracking', {}).get('enabled', True)
        tracking_duration = CONFIG.get('tracking', {}).get('duration', 60)

        if not tracking_enabled:
            print("ğŸ“· è¿½å°¾æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™")
            return person

        print(f"ğŸ¯ äººç‰©è¿½å°¾é–‹å§‹ï¼ˆ{tracking_duration}ç§’é–“ï¼‰")
        start_time = time.time()

        # ç”»åƒã‚µã‚¤ã‚ºå–å¾—
        img_height, img_width = initial_image.shape[:2]
        center_x = img_width / 2
        center_y = img_height / 2

        # è¨±å®¹ç¯„å›²ï¼ˆç”»é¢ä¸­å¿ƒã‹ã‚‰ï¼‰
        tolerance_x = img_width * 0.1  # ç”»é¢å¹…ã®10%

        tracked_person = person

        while (time.time() - start_time) < tracking_duration:
            # ç¾åœ¨ã®ç”»åƒã‚’å–å¾—
            image = self.capture_snapshot()
            if image is None:
                print("âš ï¸ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—å¤±æ•—")
                break

            # äººç‰©æ¤œå‡º
            persons = self.detect_person(image)

            if not persons:
                print("âŒ äººç‰©ã‚’è¦‹å¤±ã„ã¾ã—ãŸ")
                del image
                break

            # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„äººç‰©ã‚’é¸æŠ
            tracked_person = max(persons, key=lambda p: p['confidence'])
            bbox = tracked_person['bbox']

            # äººç‰©ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
            person_center_x = (bbox[0] + bbox[2]) / 2
            person_center_y = (bbox[1] + bbox[3]) / 2

            # ç”»é¢ä¸­å¿ƒã‹ã‚‰ã®ãšã‚Œã‚’è¨ˆç®—
            offset_x = person_center_x - center_x
            offset_y = person_center_y - center_y

            # ç”»é¢ä¸­å¿ƒã«è¿‘ã‘ã‚Œã°è¿½å°¾ä¸è¦
            if abs(offset_x) < tolerance_x:
                print(f"âœ… ä¸­å¿ƒã«æ•æ‰ï¼ˆã‚ªãƒ•ã‚»ãƒƒãƒˆ: {offset_x:.0f}pxï¼‰")
            else:
                # ã‚«ãƒ¡ãƒ©ã‚’ç§»å‹•
                # æ­£è¦åŒ–ã•ã‚ŒãŸé€Ÿåº¦ï¼ˆç”»é¢ç«¯ã«è¿‘ã„ã»ã©é€Ÿãï¼‰
                pan_speed = max(-0.3, min(0.3, offset_x / center_x * 0.2))

                print(f"ğŸ¯ è¿½å°¾ä¸­... ã‚ªãƒ•ã‚»ãƒƒãƒˆ: {offset_x:.0f}px, é€Ÿåº¦: {pan_speed:.3f}")

                self.move_camera_smooth(pan_speed, 0, 0.3)

            # ç”»åƒå‰Šé™¤
            del image

            # çŸ­ã„å¾…æ©Ÿ
            time.sleep(0.5)

        elapsed = time.time() - start_time
        print(f"âœ… è¿½å°¾å®Œäº†ï¼ˆ{elapsed:.1f}ç§’é–“ï¼‰")

        return tracked_person
    
    def handle_detection(self, angle, image, person):
        """äººç‰©æ¤œå‡ºæ™‚ã®å‡¦ç†"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # å‰å›ã¨æ¯”è¼ƒ
        comparison = self.compare_with_previous(image, person)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²
        event = {
            'timestamp': timestamp,
            'state': self.state,
            'camera_angle': angle,
            'posture': person['posture'],
            'confidence': person['confidence'],
            'same_position': comparison['same_position'],
            'similarity': comparison['similarity_ssim'],
            'position_diff': comparison['position_diff'],
            'next_interval': self.interval
        }
        
        self.today_data['events'].append(event)
        self.today_data['summary']['total_detections'] += 1
        self.today_data['summary']['last_activity'] = timestamp
        
        if self.today_data['summary']['first_activity'] is None:
            self.today_data['summary']['first_activity'] = timestamp
        
        # çŠ¶æ…‹é·ç§»
        if comparison['same_position']:
            print(f"ğŸ“ åŒã˜ä½ç½®ï¼ˆé¡ä¼¼åº¦: {comparison['similarity_ssim']:.2f}ï¼‰")
            
            if person['posture'] == 'lying':
                print("âš ï¸ æ¨ªãŸã‚ã£ã¦ã„ã‚‹å§¿å‹¢ã‚’æ¤œå‡º")
                self.handle_lying_detection(angle, person)
            else:
                # æ­£å¸¸
                self.state = "detected_active"
                self.interval = CONFIG['scan_intervals']['detected_active']
                print(f"âœ… æ­£å¸¸ï¼ˆ{person['posture']}ï¼‰- æ¬¡å›: {self.interval}ç§’å¾Œ")
        else:
            print(f"ğŸš¶ ç§»å‹•æ¤œå‡ºï¼ˆ{person['posture']}ï¼‰")
            self.state = "detected_once"
            self.interval = CONFIG['scan_intervals']['detected_once']
        
        self.last_detection_time = datetime.now()
        
        # ç”»åƒå‰Šé™¤
        del image
    
    def handle_lying_detection(self, angle, person):
        """è»¢å€’æ¤œçŸ¥å‡¦ç†"""
        print(f"â³ {CONFIG['fall_detection']['recheck_delay']}ç§’å¾Œã«å†ç¢ºèª...")
        time.sleep(CONFIG['fall_detection']['recheck_delay'])
        
        # å†ã‚¹ã‚­ãƒ£ãƒ³
        self.move_camera(angle)
        image = self.capture_snapshot()
        persons = self.detect_person(image)
        
        if persons and persons[0]['posture'] == 'lying':
            print("ğŸš¨ ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆ: è»¢å€’ã®å¯èƒ½æ€§ï¼")
            self.send_emergency_alert("è»¢å€’æ¤œçŸ¥", {
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'posture': 'lying',
                'recheck': True
            })
            self.today_data['summary']['lying_events'] += 1
            self.today_data['summary']['alerts'].append({
                'type': 'fall_detection',
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
        else:
            print("âœ… å†ç¢ºèª: æ­£å¸¸")
        
        del image
    
    def send_emergency_alert(self, alert_type, data):
        """ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        # TODO: ãƒ¡ãƒ¼ãƒ«é€ä¿¡å®Ÿè£…
        print(f"\n{'='*60}")
        print(f"ğŸš¨ ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆ: {alert_type}")
        print(f"æ™‚åˆ»: {data['timestamp']}")
        print(f"è©³ç´°: {json.dumps(data, ensure_ascii=False, indent=2)}")
        print(f"{'='*60}\n")
        
        # ãƒ­ã‚°è¨˜éŒ²
        log_file = LOG_DIR / f"alerts_{datetime.now().strftime('%Y-%m')}.log"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{data['timestamp']} - {alert_type}: {json.dumps(data, ensure_ascii=False)}\n")
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        print("\nğŸ  è¦‹å®ˆã‚Šãƒãƒ­ - ç›£è¦–é–‹å§‹")
        print(f"é–“éš”: {self.interval}ç§’")
        
        try:
            while True:
                # å¤œé–“ãƒ¢ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                if self.is_night_mode():
                    self.interval = CONFIG['scan_intervals']['night_mode']
                    print(f"ğŸŒ™ å¤œé–“ãƒ¢ãƒ¼ãƒ‰ï¼ˆ{self.interval}ç§’é–“éš”ï¼‰")
                
                # ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
                print(f"\nğŸ” ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹ - {datetime.now().strftime('%H:%M:%S')}")
                angle, image, person = self.scan_area()
                
                if person:
                    self.handle_detection(angle, image, person)
                else:
                    print("âŒ æœªæ¤œå‡º")
                    self.state = "not_detected"
                    self.interval = CONFIG['scan_intervals']['not_detected']
                    print(f"æ¬¡å›: {self.interval}ç§’å¾Œ")
                
                # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                self.save_today_data()
                
                # å¾…æ©Ÿ
                time.sleep(self.interval)
                
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ è¦‹å®ˆã‚Šãƒãƒ­ã‚’åœæ­¢ã—ã¾ã™...")
            self.save_today_data()

if __name__ == "__main__":
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    
    # å®Ÿè¡Œ
    halo = MimamoriHalo()
    halo.run()
